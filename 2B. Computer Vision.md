## 2B. Computer Vision

1. Intro
   1. TorchVision
      1. 미리 트레인된 다양한 모델들을 가지고 있음.
   2. ImageNet
      1. 이미지 인식 챌린지 2010년부터 시작됨
2. AlexNet
   1. 이전에 비해 큰폭으로 발달
   2. RELU와 드롭아웃으로 혁신화
   3. Heavy data augmentation
3. ZFNet
   1. AlexNet 기ㅂ반, CONV1이 작음. Deconvolutional한 이미지
4. VGGNet
   1. 간단하지만 3n3 conv와 2n2 pool로 이루어진 deep architecture
   2. 채널 차원이 층이 늘어날수록 커진다.
   3. 메모리는 초반 CONV에서 대부분 사용하고, 대부분의 params는 후반의 풀리커넥티드층에 적용
5. GoogleNet
   1. VGG처럼 딥하지만 3%의 파라미터만 사용
   2. 완전연결층이 없음.
   3. 인셉션 모듈이 스택된것. 
   4. Network가 끝나기 전에 분류기를 중간에 추가할 수 있다.
6. ResNet
   1. 152개층. 사람의 퍼포먼스보다 낮은 에러
   2. shortcut을 추가함 -> Residual Network
7. SqueezeNet
   1. SENet
   2. 글로벌 풀링 모듈을 추가 + 완전연결에 적응형 재가중치 피쳐(?)
   3. 병목현상 사용
8. Comparison
   1. Inception-v4가 성능도 좋고 메모리도 덜먹음.
   2. 빠른 훈련
      1. 32K의 미니배치 사이즈 사용하여 1024 테슬라 P100 GPU에서 15분
9. Localization, Detection, Segmentation
   1. 로컬리제이션 : 어떤 것의 위치를 식별해냄
   2. 디텍션 : 여러개가 있을때?
      1. 사진을 잘게잘라 분류하면 계산이 너무 복잡해짐!
10. YOLO, SSD
    1. You Only Look Once
    2. Single Shot Detector
11. Region Proposal Methods(R-CNN)
    1. 이미지의 region을 특정해서 잘라 의미있을 것 같은 곳을 구분함
    2. 패스터 R-CNN
    3. 마스크 R-CNN
       1. 패스터 뿐만아니라 Instance segmentation module를 통과함
    4. 완전 합성곱 Net
       1. 오리지널 스케일에서의 Conv는 expensive함
    5. 업샘플링
       1. 언풀링 : 풀링과정에서 어떤 것이 선택됐는지 기억했다가 업샘플링때 사용하기
       2. Transpose conv + dilated conv
          1. 학습가능한 업샘플링
          2. 띄엄띄엄 conv
12. Advanced Task
    1. 라벨링된 훈련데이터에서 잘 돌아감
13. Adversarial Attack
    1. 약간의 그림 수정으로 모델을 망칠 수 있음.
    2. 블랙박스모델은 안되지만, 화이트박스는 모델 파라미터에 접근하는 공격가능
    3. 공격 : 경사하강의 방향의 인풋을 수정
    4. 방어 
       1. 그런 샘플을 훈련
       2. 클래스 결정 경계를 스무스하게 바꿈.

14. 스타일 트랜스퍼
    1. 화풍을 훈련하여 다른 이미지에 그 화풍을 반영하는 모델